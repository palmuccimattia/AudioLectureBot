# ðŸŽ™ï¸ AudioLecture â€” Bot Telegram per Trascrizione Audio di Lezioni

> **Progetto esplorativo** Â· Febbraio 2026
> Bot Telegram gratuito che trascrive registrazioni audio universitarie in PDF, monetizzato tramite sponsorizzazioni.

---

## Indice

- [Idea e obiettivo](#idea-e-obiettivo)
- [Architettura](#architettura)
- [Stack tecnologico](#stack-tecnologico)
- [Flusso operativo](#flusso-operativo)
- [Worker EC2 â€” Componente Core](#worker-ec2--componente-core)
- [Workflow n8n](#workflow-n8n)
- [Modello economico](#modello-economico)
- [Confronto con Turboscribe.ai](#confronto-con-turboscribeai)
- [PerchÃ© il progetto si Ã¨ fermato](#perchÃ©-il-progetto-si-Ã¨-fermato)
- [Struttura del repository](#struttura-del-repository)

---

## Idea e obiettivo

AudioLecture nasce dall'osservazione che migliaia di studenti italiani registrano le lezioni universitarie ma poi faticano a rielaborarle. L'obiettivo era costruire un bot Telegram **completamente gratuito** che riceve un file audio e restituisce un PDF con la trascrizione completa e timestamp.

La monetizzazione sarebbe avvenuta esclusivamente tramite **sponsorizzazioni** (messaggio pubblicitario inviato prima di ogni trascrizione), senza alcun piano a pagamento.

---

## Architettura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Telegram    â”‚â”€â”€â”€â”€â–¶â”‚   Bot API Server  â”‚â”€â”€â”€â”€â–¶â”‚        n8n           â”‚
â”‚   (utente)    â”‚â—€â”€â”€â”€â”€â”‚   (proxy locale)  â”‚â—€â”€â”€â”€â”€â”‚   (orchestratore)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                              Start/Stop EC2
                                                         â”‚
                                                         â–¼
                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â”‚  EC2 g4dn.xlarge     â”‚
                                                â”‚  NVIDIA T4 GPU       â”‚
                                                â”‚  faster-whisper      â”‚
                                                â”‚  FastAPI + ReportLab â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componenti

| Componente | Ruolo | Hosting |
|---|---|---|
| **Bot API Server** | Proxy Telegram locale (nessun limite 20 MB) | EC2 t3.micro |
| **n8n** | Orchestratore: webhook, coda, start/stop EC2 | EC2 t3.medium (sempre acceso) |
| **Worker GPU** | Trascrizione audio + generazione PDF | EC2 g4dn.xlarge **on-demand** (acceso solo quando serve) |

La scelta **on-demand** (invece di spot) garantisce startup in 1â€“2 minuti e zero rischio di interruzioni. Il costo fisso del worker Ã¨ ~$5/mese quando fermo (solo storage EBS).

---

## Stack tecnologico

### Worker (Python)

| Libreria | Versione | Scopo |
|---|---|---|
| `faster-whisper` | 1.1.0 | Trascrizione audio con CTranslate2 (INT8 GPU) |
| `fastapi` | 0.115.0 | Server HTTP per ricevere job da n8n |
| `uvicorn` | 0.30.6 | ASGI server |
| `reportlab` | 4.2.2 | Generazione PDF |
| `requests` | 2.32.3 | Download audio da Telegram, callback a n8n |

**Base image Docker:** `pytorch/pytorch:2.4.1-cuda12.1-cudnn9-runtime`
**GPU:** NVIDIA T4 â€” compute type INT8 via CTranslate2

### Infrastruttura

- **AWS EC2 g4dn.xlarge** â€” 4 vCPU, 16 GB RAM, GPU T4 16 GB VRAM
- **AMI:** Deep Learning OSS Nvidia Driver AMI GPU PyTorch 2.9 (Ubuntu 24.04)
- **n8n** â€” orchestrazione workflow via self-hosted
- **Google Sheets** â€” database MVP (users + transcription_queue)
- **Docker** con `--restart=always` per auto-start al boot dell'istanza

---

## Flusso operativo

```
1. Utente invia audio al bot Telegram
         â”‚
         â–¼
2. n8n riceve il webhook
   â”œâ”€ Se primo utilizzo â†’ flusso GDPR (consenso inline)
   â””â”€ Se utente registrato:
      â”œâ”€ Invia messaggio sponsor
      â”œâ”€ Conferma "ðŸ“ Trascrizione in coda..."
      â””â”€ Salva job su Google Sheets (status: pending)
         â”‚
         â–¼
3. Cron n8n (ogni 3 min)
   â”œâ”€ Legge job pending da Sheets
   â”œâ”€ Controlla stato EC2 â†’ se stopped: StartInstances
   â”œâ”€ Polling health check su /health
   â””â”€ POST /transcribe al worker
         â”‚
         â–¼
4. Worker EC2
   â”œâ”€ Download audio da Telegram (via file_id)
   â”œâ”€ Trascrizione con faster-whisper (modello small, INT8, GPU)
   â”œâ”€ Generazione PDF con timestamp (ReportLab)
   â”œâ”€ Invio PDF all'utente via Telegram
   â””â”€ Callback a n8n â†’ update status completed
         â”‚
         â–¼
5. n8n verifica coda vuota da >10 min â†’ StopInstances
```

---

## Worker EC2 â€” Componente Core

### API FastAPI

```
GET  /health       â†’ {"status": "healthy", "gpu": true, "queue_size": 0}

POST /transcribe   â†’ {"status": "queued", "job_id": "..."}
Body: {
    "file_id": "...",
    "chat_id": 123456,
    "user_id": 789,
    "callback_url": "https://n8n-host/webhook/callback",
    "sponsor": {
        "name": "Sponsor",
        "footer_text": "Offerto da Sponsor"
    }
}
```

### Performance faster-whisper

Il modello `small` con compute type `int8` su GPU T4 ha raggiunto un **rapporto di elaborazione di 26.5x** rispetto al tempo reale.

| Audio | Tempo elaborazione |
|---|---|
| 1 ora | ~2 min 15 sec |
| 30 min | ~1 min 7 sec |
| 5 min | ~11 sec |

### Docker build

Il modello viene scaricato durante il `docker build` (non al primo avvio), rendendo il container pronto immediatamente.

```dockerfile
FROM pytorch/pytorch:2.4.1-cuda12.1-cudnn9-runtime
RUN apt-get update && apt-get install -y ffmpeg git
RUN pip install -r requirements.txt
# Pre-download modello durante build
RUN python -c "from faster_whisper import WhisperModel; WhisperModel('small', device='cpu', compute_type='int8')"
CMD ["uvicorn", "worker:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]
```

---

## Workflow n8n

Il progetto include due workflow n8n principali (in `n8n/workflows/`):

### 1. Queue Processor (`queue-processor.json`)
Cron ogni 3 minuti. Gestisce l'intera pipeline:
- Lettura job pending da Google Sheets
- Verifica e avvio istanza EC2
- Health check worker
- Invio job al worker via HTTP POST
- Aggiornamento status in Sheets
- Shutdown EC2 quando coda vuota

### 2. Transcription Callback (`transcription-callback.json`)
Webhook ricevuto dal worker al completamento:
- Aggiorna status `completed` o `failed` su Sheets
- Verifica se la coda Ã¨ vuota
- Se inattiva da >10 min â†’ Stop EC2

### Bot principale (n8n.evolvidigital.it)
Il workflow principale gestisce:
- Onboarding GDPR con pulsante inline di consenso
- Distinzione callback / messaggi audio / altri messaggi
- Accodamento trascrizioni su Google Sheets

---

## Modello economico

### Costi variabili per trascrizione

Con faster-whisper su EC2 g4dn.xlarge ($0.526/ora), il costo variabile per trascrizione dipende dalla durata dell'audio:

```
Costo per trascrizione = (durata_audio_ore / 26.5) Ã— $0.526

Esempi:
  Audio 30 min  â†’ 0.5 / 26.5 Ã— $0.526 â‰ˆ $0.010
  Audio 60 min  â†’ 1.0 / 26.5 Ã— $0.526 â‰ˆ $0.020
  Audio 90 min  â†’ 1.5 / 26.5 Ã— $0.526 â‰ˆ $0.030
```

**Costo medio stimato per trascrizione: ~$0.01â€“0.03**

### Costi fissi

I costi fissi dell'infrastruttura (n8n su t3.medium ~$30/mese, Bot API Server ~$8/mese, storage EBS ~$5/mese) erano **giÃ  sostenuti da un'altra attivitÃ ** preesistente sullo stesso account AWS. Questo significa che il costo incrementale reale del progetto era composto quasi interamente dai costi variabili di compute GPU â€” rendendo il modello economico particolarmente favorevole nella fase iniziale.

### Ricavi per trascrizione (stima)

Con un solo sponsor in modalitÃ  *In-Trascrizione* (CPC â‚¬0.25, CTR 3%):

```
Revenue per trascrizione = CPC Ã— CTR = â‚¬0.25 Ã— 3% = â‚¬0.0075
```

Con 1.000 trascrizioni/mese:
- Costo variabile GPU: ~$15 (~â‚¬14)
- Revenue sponsor: â‚¬7.50
- Break-even stimato: ~2.000 trascrizioni/mese con CTR 3%

Il modello diventa profittevole quando si raggiunge un volume sufficiente di utenti attivi settimanali (coda che mantiene l'EC2 accesa in modo efficiente) combinato con piÃ¹ slot sponsor.

---

## Confronto con Turboscribe.ai

Turboscribe.ai Ã¨ il competitor diretto piÃ¹ noto: trascrizione audio illimitata a $10/mese (annuale) o $20/mese, basata su Whisper Large v3 su GPU dedicate.

| | **Turboscribe** | **AudioLecture** |
|---|---|---|
| Prezzo utente | $10â€“20/mese | â‚¬0 (sempre gratis) |
| Modello revenue | Freemium SaaS | Sponsor-based |
| Target | Globale, qualsiasi utente | Studenti universitari italiani |
| Costo server | Always-on (GPU dedicata) | On-demand (acceso solo quando lavora) |
| Limite free | 3 file/giorno Ã— 30 min | Nessuno |
| Accuratezza modello | Whisper Large v3 | Whisper Small (qualitÃ  inferiore) |
| LTV utente | Alto ($120â€“240/anno) | â‚¬0 (gratuito) |
| ScalabilitÃ  revenue | Lineare con utenti paganti | Legata ai CPM sponsor |

### Osservazioni

Turboscribe si basa su un classico modello freemium: il piano gratuito (3 file/giorno) serve come esca per la conversione al piano pagamento. I costi marginali per trascrizione su GPU sono bassissimi (~$0.007/ora audio con faster-whisper), quindi anche utenti con uso elevato restano ampiamente profittevoli a $10/mese.

AudioLecture sceglie una strada opposta: **zero barriera all'adozione** (massimizza il numero di utenti) e monetizzazione tramite attenzione pubblicitaria. Questo funziona meglio in una nicchia verticale dove il passaparola Ã¨ forte (studenti universitari) ma Ã¨ piÃ¹ difficile da scalare in termini di revenue rispetto a un SaaS.

---

## PerchÃ© il progetto si Ã¨ fermato

Il progetto Ã¨ stato interrotto nella fase MVP funzionante (end-to-end pipeline operativa per audio <20 MB) per le seguenti considerazioni:

1. **Unit economics sfavorevoli a basso volume** â€” il break-even richiede un volume di trascrizioni difficile da raggiungere con un singolo sponsor all'inizio
2. **Dipendenza da sponsor** â€” trovare sponsor prima di avere utenti Ã¨ il classico problema dell'uovo e della gallina
3. **Competizione con servizi gratuiti esistenti** â€” Whisper Ã¨ open source e molti studenti possono usarlo localmente o tramite tool gratuiti
4. **ComplessitÃ  operativa** â€” gestire EC2 on/off, Bot API Server, n8n, Google Sheets introduce molti punti di failure per un MVP

L'esperienza ha comunque permesso di esplorare in profonditÃ : infrastruttura AWS GPU on-demand, faster-whisper con ottimizzazioni INT8, orchestrazione con n8n, workflow Telegram bot con consenso GDPR.

---

## Struttura del repository

```
AudioLectureBot/
â”œâ”€â”€ README.md                          # Questo file
â”œâ”€â”€ CLAUDE.md                          # Note architetturali dettagliate
â”œâ”€â”€ ec2-worker-config.txt              # Comando AWS CLI per lanciare il worker
â”‚
â”œâ”€â”€ worker/
â”‚   â”œâ”€â”€ Dockerfile                     # Container PyTorch + faster-whisper
â”‚   â”œâ”€â”€ requirements.txt               # Dipendenze Python
â”‚   â”œâ”€â”€ config.py                      # Variabili d'ambiente
â”‚   â”œâ”€â”€ worker.py                      # FastAPI server + asyncio job queue
â”‚   â”œâ”€â”€ transcriber.py                 # Wrapper faster-whisper
â”‚   â”œâ”€â”€ pdf_generator.py               # Generazione PDF con ReportLab
â”‚   â”œâ”€â”€ telegram_client.py             # Download audio + invio PDF
â”‚   â””â”€â”€ startup.sh                     # Setup one-shot EC2 (Docker + NVIDIA)
â”‚
â”œâ”€â”€ n8n/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ queue-processor.json       # Cron: gestione coda + EC2 start/stop
â”‚       â””â”€â”€ transcription-callback.json # Webhook: ricezione risultato da worker
â”‚
â””â”€â”€ screenshots/                       # Screenshot del progetto durante lo sviluppo
```

### File da escludere dal repository pubblico

- `connect_istance.bat` â€” contiene IP dell'istanza EC2
- `.env` â€” variabili d'ambiente con token e credenziali
- `.claude/` â€” configurazione locale Claude Code

---

## Variabili d'ambiente necessarie

```env
TELEGRAM_BOT_TOKEN=      # Token da BotFather
BOT_API_SERVER_URL=      # http://<ip>:8081 (Bot API Server locale)
WHISPER_MODEL=small      # small | medium | large-v3
TEMP_DIR=/tmp/audiolecture
```

---

*Progetto esplorativo â€” Febbraio 2026*
